{"company":[{"id":"247","name":"ScraperWiki","summary":"ScraperWiki is a web-based platform for collaboratively building programs to extract and analyze public (online) data, in a wiki-like fashion. \"Scraper\" refers to screen scrapers, programs that extract data from websites. \"Wiki\" means that any user with programming experience can create or edit such programs for extracting new data, or for analyzing existing datasets. The main use of the website i","details":"ScraperWiki is a web-based platform for collaboratively building programs to extract and analyze public (online) data, in a wiki-like fashion. \"Scraper\" refers to screen scrapers, programs that extract data from websites. \"Wiki\" means that any user with programming experience can create or edit such programs for extracting new data, or for analyzing existing datasets. The main use of the website is providing a place for programmers and journalists to collaborate on analyzing public data","website":"https:\/\/scraperwiki.com\/docs\/api","twitter":"https:\/\/twitter.com\/#!\/scraperwiki","github":"https:\/\/github.com\/scraperwiki","blog":"http:\/\/blog.scraperwiki.com\/","blogrss":"http:\/\/blog.scraperwiki.com\/feed\/","logo":"http:\/\/kinlane-productions.s3.amazonaws.com\/api-evangelist-site\/company\/798px-ScraperWiki_logo.png","logo_width":"0","screenshot":"http:\/\/kinlane-productions.s3.amazonaws.com\/api-evangelist-site\/api\/ScraperWiki-Screenshot.png","tags":"Data,Hacker Storytelling,Harvesting,Scraping,Stack,Wiki"},{"id":"1569","name":"PageMunch","summary":"Page Munch is a simple API that allows you to turn web pages into rich, structured JSON. Easily extract photos, videos, event, author and other metadata from any page on the internet in milliseconds.","details":"Page Munch is a simple API that allows you to turn web pages into rich, structured JSON. Easily extract photos, videos, event, author and other metadata from any page on the internet in milliseconds.","website":"http:\/\/www.pagemunch.com","twitter":"https:\/\/twitter.com\/PageMunch","github":"https:\/\/github.com\/PageMunch","blog":"","blogrss":"","logo":"http:\/\/kinlane-productions.s3.amazonaws.com\/api-evangelist-site\/company\/logos\/page-munch-logo.png","logo_width":"125","screenshot":"http:\/\/kinlane-productions.s3.amazonaws.com\/ap-evangelist-site\/api\/screenshots\/8900_pagemunch.png","tags":"JSON,REST,scraper,Scraping,Stack,Utility"},{"id":"1500","name":"Web Scrape Master","summary":"Scrape web without writing code for it; To create value from the sea of data being published over web. Data is Currency.API. Web scrape master provides a very simple API for retrieving scrape data.","details":"Scrape web without writing code for it; To create value from the sea of data being published over web. Data is Currency.API. Web scrape master provides a very simple API for retrieving scrape data.","website":"http:\/\/motyar.info\/webscrapemaster\/","twitter":"https:\/\/twitter.com\/motyar","github":"","blog":"http:\/\/motyar.blogspot.com\/","blogrss":"http:\/\/motyar.blogspot.com\/feeds\/posts\/default?alt=rss","logo":"http:\/\/kinlane-productions.s3.amazonaws.com\/api-evangelist-site\/company\/logos\/web-scrape-master-logo-2.png","logo_width":"150","screenshot":"http:\/\/kinlane-productions.s3.amazonaws.com\/ap-evangelist-site\/api\/screenshots\/8364_web_scrape_master.png","tags":"Content,Data,internet,NLP,REST,Scraping,Stack,Tools"},{"id":"1728","name":"import.io","summary":"Importio turns the web into a database, releasing the vast potential of data trapped in websites. Allowing you to identify a website, select the data and treat it as a table in your database. In effect transform the data into a row and column format. You can then add more websites to your data set, the same as adding more rows and query in real-time to access the data.","details":"Importio turns the web into a database, releasing the vast potential of data trapped in websites. Allowing you to identify a website, select the data and treat it as a table in your database. In effect transform the data into a row and column format. You can then add more websites to your data set, the same as adding more rows and query in real-time to access the data.","website":"http:\/\/docs.import.io\/","twitter":"https:\/\/twitter.com\/importio","github":"","blog":"http:\/\/blog.import.io\/","blogrss":"","logo":"http:\/\/kinlane-productions.s3.amazonaws.com\/api-evangelist-site\/company\/1728_logo.png","logo_width":"0","screenshot":null,"tags":"Analytics,Data,Scraping"},{"id":"1920","name":"Common Crawl","summary":"Common Crawl is a non-profit foundation dedicated to providing an open repository of web crawl data that can be accessed and analyzed by everyone. Common Crawl Foundation is a California 501(c)(3) registered non-profit founded by Gil Elbaz with the goal of democratizing access to web information by producing and maintaining an open repository of web crawl data that is universally accessible and an","details":"Common Crawl is a non-profit foundation dedicated to providing an open repository of web crawl data that can be accessed and analyzed by everyone. Common Crawl Foundation is a California 501(c)(3) registered non-profit founded by Gil Elbaz with the goal of democratizing access to web information by producing and maintaining an open repository of web crawl data that is universally accessible and analyzable.","website":"http:\/\/commoncrawl.org\/","twitter":"https:\/\/twitter.com\/CommonCrawl","github":"","blog":"http:\/\/commoncrawl.org\/blog\/","blogrss":"","logo":"http:\/\/kinlane-productions.s3.amazonaws.com\/api-evangelist-site\/company\/logos\/common-crawl-logo-2.png","logo_width":"150","screenshot":null,"tags":"Scraping"},{"id":"1922","name":"ConvExtra","summary":"Convextra allows you collect valuable data from internet and represents it in easy-to-use CVS format for forther utilization.","details":"Convextra allows you collect valuable data from internet and represents it in easy-to-use CVS format for forther utilization.","website":"http:\/\/convextra.com\/","twitter":"","github":"","blog":"","blogrss":"","logo":"http:\/\/kinlane-productions.s3.amazonaws.com\/api-evangelist-site\/company\/logos\/convextra-logo.png","logo_width":"150","screenshot":null,"tags":"Scraping"},{"id":"1921","name":"Screen Scraper","summary":"Copying text from a web page. Clicking links. Entering data into forms and submitting. Iterating through search results pages. Downloading files (PDF, MS Word, images, etc.).","details":"Copying text from a web page. Clicking links. Entering data into forms and submitting. Iterating through search results pages. Downloading files (PDF, MS Word, images, etc.).","website":"http:\/\/screen-scraper.com\/","twitter":"","github":"","blog":"http:\/\/blog.screen-scraper.com\/","blogrss":"http:\/\/feeds.feedburner.com\/screen-scrapeable","logo":"http:\/\/kinlane-productions.s3.amazonaws.com\/api-evangelist-site\/company\/logos\/screen-scraper-logo.png","logo_width":"150","screenshot":null,"tags":"Scraping"}],"published":"12\/24\/2013"}